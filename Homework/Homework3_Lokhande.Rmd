---
title: 'Homework 3: Model Validation'
author: "Snehal Lokhande"
date: "2023-01-29"
output:
  pdf_document: default
  html_document: default
---


```{r}
library(tidyverse)
library(dplyr)
```

## 1. Data set <PGA.csv> Download <PGA.csv>contains statistics of performance and winnings for 196 PGA tour participants during 2004 season [https://www.pgatour.com/]. Here is the list of variables: Name, Age, Average Drive (Yards), Driving accuracy (percent), Greens on regulation (%), Average # of putts, Save Percent, Money Rank, # Events, Total Winnings ($), Average winnings ($). Please read PGA data (PGA.csv) into R and visualize it. Note that Average winnings = Total Winnings/# Events. For this data set, fit a multiple linear regression to the data. Use Average winnings as the response variable and use Age, Average Drive (Yards), Driving Accuracy (percent), Greens on Regulation (%), Average # of Putts, Save Percent, and # Events as covariates. 


```{r}
pga <- read.csv("PGA.csv", header = T, stringsAsFactors = FALSE)
head(pga, 5)
```

Some brief visualizations:

Let’s see the spread of the players’ ages, average drives, and driving accuracy.


```{r}
hist(pga$Age,xlab = "Years",col = "pink", border = "black" , main= "Age of Players")
```
```{r}
hist(pga$AverageDrive,xlab = "Yards",col = "pink", border = "black" , main= "Average Drive")
```
```{r}
hist(pga$DrivingAccuracy,xlab = "Percentage",col = "pink", border = "black" , main= "Driving Acurracy")
```
Observations from the Histograms:

Most players seem to be in their 30’s, but ages range from low 20’s to mid 50’s.

The players’ average drives center around ~285 yards, and the distribution of average drive across all players is roughly normal.

Do we have any players who win significantly more money than the majority of players? We can look for outliers.


```{r}
boxplot(pga$TotalWinnings,main = "Total Winnings",ylab = "Dollars (1000s)")

```
```{r}
boxplot(pga$AverageWinnings,main = "Average Winnings",ylab = "Dollars (1000s)")

```
Observations from these boxplots:

The distribution of winnings is heavily skewed to the right. There are many players who can be considered outliers. This means there are players that have won dramatiaclly more money or are dramatically more successful on average than the majority of players.

There is one outlier even farther away than the other outliers in the “Total Winnings” boxplot. We do not see a similar dramatic outlier in the “Average Winnings” boxplot. This may indicate that one player won an important tournament with a large cash prize, but lost enough other tournaments that he is not as successful on average.

### Part II
1. For this data set, fit a multiple linear regression to the data.
2. & 3.


```{r}
pga_fit <- lm(AverageWinnings ~ Age + AverageDrive + DrivingAccuracy + GreensonRegulation + AverageNumofPutts + SavePercent + NumEvents, data = pga)
summary(pga_fit)
```
4. A brief look at the summary output of the requested linear model indicates that the model is signficant (suing the F test, P-value < 2.2e-16 which is significant at the 1% level.)



## 2. Using the fitted regression in previous question, obtain the prediction of the response variable for a new player with Age = 35, AverageDrive = 287, DrivingAccuracy = 64, GreensonRegulation = 64.9, AverageNumofPutts = 1.778, SavePercent = 48, NumEvents = 26. Provide a prediction interval and explain what it means. 


2.& 3.

```{r}
# create player 2
pred_data2 <- data.frame(Age=35, AverageDrive=287, DrivingAccuracy=64, GreensonRegulation=64.9, AverageNumofPutts=1.778, SavePercent=48, NumEvents=26)

# apply player's stats and predict their Average Winnings
pred_val2 <- predict(pga_fit, pred_data2, interval = "prediction", level = 0.95, type = "response")
two <- cbind(pred_data2, pred_val2)  # will be used later
pred_val2

```

Given the specific values for the covariates(above), the predicted value of AverageWinnings for this player is $46,721. We can say with 95% confidence that the true average winnings given someone with the stats represented in the covariates above is between zero dollars (because you can’t win negative dollars ) and $128,678.



## 3. Similarly, make another prediction for the case of Age = 42, AverageDrive = 295, DrivingAccuracy = 69, GreensonRegulation = 67.7, AverageNumofPutts = 1.80, SavePercent = 54, NumEvents = 30. 

2.& 3.

```{r}
# Create player 3
pred_data3 <- data.frame(Age=42, AverageDrive=295, DrivingAccuracy=69, GreensonRegulation=67.7, AverageNumofPutts=1.80, SavePercent=54, NumEvents=30)

# apply player's stats and predict their Average Winnings
pred_val3 <- predict(pga_fit, pred_data3, interval = "prediction", level = 0.95, type = "response")
three <- cbind(pred_data3, pred_val3)  # will be used later
pred_val3

```

4.Given the specific values for the covariates (above), the predicted value of AverageWinnings for this player is $34,219. We can say with 95% confidence that the true average winnings given someone with the stats represented in the covariates above is between zero dollars (because you can’t win negative dollars) and $118,281.


## 4. Make a third prediction for the case of Age = 45, AverageDrive = 320, DrivingAccuracy = 70, GreensonRegulation = 67.7, AverageNumofPutts = 1.80, SavePercent = 54, NumEvents = 30. 

2.& 3.

```{r}
# create player 4
pred_data4 <- data.frame(Age=45, AverageDrive=320, DrivingAccuracy=70, GreensonRegulation=67.7, AverageNumofPutts=1.80, SavePercent=54, NumEvents=30)

# apply player's stats and predict their Average Winnings
pred_val4 <- predict(pga_fit, pred_data4, interval = "prediction", level = 0.95, type = "response")
four <- cbind(pred_data4, pred_val4)  # will be used later
pred_val4

```

4.Given the specific values for the covariates (above), the predicted value of AverageWinnings for this player is $27,728. We can say with 95% confidence that the true average winnings given someone with the stats represented in the covariates above is between zero dollars (because you can’t win negative dollars) and $121,367.


## 5. Compare the predictions from previous questions, what do you observe? For example, which prediction interval is wider? which prediction dosen’t make sense? Among these predictions, which one is extrapolation? And why? 

Part I

1. Compare the Prediction Intervals of all three players (Q2-4) and note observations.

2. & 3.


```{r}
pred_table <- rbind(two, three, four)
pred_table <- as.data.frame(pred_table)
pred_table <- mutate(pred_table, upr-lwr)
pred_table

```

A few observations:

The predictions with negative winnings do not make sense. The amount of Zero Dollars should be imputted in the lwr bound of the prediction interval.
The player with the longest drive, highest driving accuracy, and tied for highest on all other covariates has the highest prediction interval.
Part II:
1. Use Leverage to determine which of the 3 observations are considered to be an Extrapolation.

2. & 3.

```{r}
# the maximum leverage in the given data set is calculated by the following:
max(cbind(pga, leverage = hatvalues(pga_fit))$leverage)

```

```{r}
two_new <- c(1,35,287,64,64.9,1.778,48,26)
three_new <- c(1,42,295,69,67.7,1.800,54,30)
four_new <- c(1,45,320,70,67.7,1.800,54,30)
X = model.matrix(pga_fit)
leverage2 <- t(two_new) %*% (solve(t(X) %*% X)) %*% two_new
leverage3 <- t(three_new) %*% (solve(t(X) %*% X)) %*% three_new
leverage4 <- t(four_new) %*% (solve(t(X) %*% X)) %*% four_new
rbind(leverage2, leverage3, leverage4)
```

Using leverage as our method of identifying extrapolations from our data, we can confirm that the third player used for prediction is extrapolated. The leverage of the player is 0.3125799 which is larger than the maximum leverage value in the dataset, given to be 0.1568547. This intuitively makes sense, as the prediction interval was the largest for this predicted observation.


## 6. Obtain the standardized regression coefficients and compare the influence of all variables. 

1. Obtain the standardized regression coefficients and compare the influence of all variables.

2. & 3.


```{r}
# transforming the data
library(dplyr)
pga_red <- select(pga, AverageWinnings, Age, AverageDrive, DrivingAccuracy, GreensonRegulation, AverageNumofPutts, SavePercent, NumEvents)
pga_unit_normal <- as.data.frame(apply(pga_red, 2, function(x){(x-mean(x))/sd(x)}))

# redoing the regression
pga_fit_unit_normal <- lm(AverageWinnings ~ Age + AverageDrive + DrivingAccuracy + GreensonRegulation + AverageNumofPutts + SavePercent + NumEvents, data = pga_unit_normal)

# obtain the standardized lm coefficients
pga_fit_unit_normal$coefficients

```


4.These coefficients have been standardized. The slopes of the covariates are now interpreted as such: For every 1 standard deviation increase of the covariate, the response variable will increase or decrease by the covariate’s coeffcient * 1 standard deviation (all other covariates held constant). For example, for every 1 standard deviation increase in Age, the player’s Average Winnings will decrease by 0.068 standard deviations (all other covariates held constant).
It appears as though Greens on Regulation has the biggest influence on Average Winnings, since the absolute value of the covariate’s coefficient is the largest of all coefficients.


## 7. Obtain the residuals of the fitted regression. Perform the residual analysis. What does the residual analysis tell you? For example, are all assumptions satisfied? If not, which ones are not satisfied.  


```{r}
# obtain the residuals
MSRes <- summary(pga_fit)$sigma^2
head(MSRes)


```


```{r}
# obtain the standardized residuals
std_res <- pga_fit$residuals / summary(pga_fit)$sigma
head(std_res)


```
##### Check the Normality Assumption

We can use the qqplot to determine if the normality condition is met. The condition is met (meaning the residuals are normally distributed) if the Q-Q Plot is around the 45 degree line. The plot below shows that the data has a positive skew (non-normal errors). It’s not ideal but I don’t think it’s extreme enough to cause a problem.


```{r}
qqnorm(pga_fit$residuals)
qqline(pga_fit$residuals)


```

##### Check for Equal Variance & Linearity
Here we will plot all the residuals against the fitted values of each of the regressors. If the linearity and equal variance assumptions are satisfied, we would expect the dots to be evenly distributed around zero with a constant variance across the x-axis. (Referencing the slides for this explanation). No obvious patterns appear in the graphs below, except: The graph of residuals versus fitted values appears to have a pattern. This indicates nonnormal errors.


```{r}
# Generate a residual plots
par(mfrow = c(3,3))
plot(pga$Age, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$AverageDrive, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$DrivingAccuracy, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$GreensonRegulation, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$AverageNumofPutts, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$SavePercent, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga$NumEvents, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")
plot(pga_fit$fitted.values, pga_fit$residuals, pch=20)
abline(h = 0, col = "grey")


```
##### Check for Independent Errors
There’s no time order in this data and therefore this is not applicable.

